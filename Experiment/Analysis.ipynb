{
 "cells": [
  {
   "cell_type": "code",
   "id": "a8400f7a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-19T10:08:30.052566Z",
     "start_time": "2024-08-19T10:08:29.649448Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "import json\n",
    "import os"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "acda6cd8",
   "metadata": {},
   "source": [
    "# Getting the Names of the retrieved nodes"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-19T12:30:20.979920Z",
     "start_time": "2024-08-19T12:30:20.976227Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_filtered_and_sorted_filenames(directory, keywords):\n",
    "    # Get all files and directories in the specified directory\n",
    "    all_entries = os.listdir(directory)\n",
    "    # Filter out directories and files containing \"additional_data\"\n",
    "    filenames = [entry for entry in all_entries if os.path.isfile(os.path.join(directory, entry)) and \"additional_data\" not in entry]\n",
    "\n",
    "    # shorten filenames to the actual query engine description\n",
    "    short = [name.split(\"_\")[0] for name in filenames]\n",
    "    names = {}\n",
    "    for n in range(len(short)):\n",
    "        names[short[n]] = filenames[n]\n",
    "    \n",
    "    # Create a dictionary to map keywords to filenames\n",
    "    keyword_to_filename = {keyword: None for keyword in keywords}\n",
    "\n",
    "    # Map filenames to the corresponding keyword\n",
    "    for short, filename in names.items():\n",
    "        for keyword in keywords:\n",
    "            if keyword in short:\n",
    "                keyword_to_filename[keyword] = directory + \"/\" + filename\n",
    "                break\n",
    "\n",
    "    # Sort filenames based on the given order of keywords\n",
    "    sorted_filenames = [keyword_to_filename[keyword] for keyword in keywords if keyword_to_filename[keyword] is not None]\n",
    "\n",
    "    return sorted_filenames"
   ],
   "id": "93f22b79ab58284a",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-19T10:08:39.575783Z",
     "start_time": "2024-08-19T10:08:39.572896Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def extract_control_keys(control_documents: list, type: str, index: int) -> list:\n",
    "    # extract either the names or the IDs:\n",
    "    if type == \"name\":\n",
    "        control_keys = [document['Name'] for document in control_documents[index]]\n",
    "    elif type == \"id\":\n",
    "        control_keys = [document['ID'] for document in control_documents[index]]\n",
    "    else:\n",
    "        raise ValueError(\"Type must be either 'name' or 'id'\")\n",
    "    return control_keys"
   ],
   "id": "fb969c4770b861ab",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-19T10:08:43.687128Z",
     "start_time": "2024-08-19T10:08:43.684408Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def extract_test_keys(df: pd.DataFrame, columns:list, index: int) -> pd.array:\n",
    "    nodes = df[columns]\n",
    "    return nodes.iloc[index].astype(str).values"
   ],
   "id": "accdf8a43ff80d2a",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-19T10:08:46.336608Z",
     "start_time": "2024-08-19T10:08:46.331337Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def compare_nodes(df: pd.DataFrame, control_path: str, columns: list, type: str = \"name\") -> [float, list[bool]]:\n",
    "    \n",
    "    \n",
    "    # read in the control documents\n",
    "    with open(control_path, 'r') as file:\n",
    "        control_documents = json.load(file)\n",
    "        \n",
    "    # compare if the test_keys contain all elements of the control_keys\n",
    "    # I.e. if one of the three retrieved nodes contains the name \"Umwelt\"\n",
    "    comparison: list[bool] = []\n",
    "    for i in range(len(control_documents)):\n",
    "        control_keys = extract_control_keys(control_documents, type, i)\n",
    "        test_keys = extract_test_keys(df, columns, i)\n",
    "        comparison.append(all(s in test_keys for s in control_keys))\n",
    "        \n",
    "    # calculate the ratio of true to false\n",
    "    ratio: float = np.mean(comparison)\n",
    "    \n",
    "    return ratio, comparison"
   ],
   "id": "c8d40607b649d74a",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-13T10:08:20.102529Z",
     "start_time": "2024-08-13T10:08:20.096083Z"
    }
   },
   "cell_type": "code",
   "source": [
    "keywords = [\"base\", \"rerank\", \"hybrid\", \"fusion\", \"hyde\"]\n",
    "files = get_filtered_and_sorted_filenames(\"./logs/2024-08-13_11-51-31_gpt-4o-mini_text_retrieval_only\", keywords)\n",
    "  \n",
    "files"
   ],
   "id": "bf42173d4af03e6a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./logs/2024-08-13_11-51-31_gpt-4o-mini_text_retrieval_only/base_gpt-4o-mini_text_retrieval_only_2024-08-13_11-51-31.csv',\n",
       " './logs/2024-08-13_11-51-31_gpt-4o-mini_text_retrieval_only/rerank_gpt-4o-mini_text_retrieval_only_2024-08-13_11-51-31.csv',\n",
       " './logs/2024-08-13_11-51-31_gpt-4o-mini_text_retrieval_only/hybrid_gpt-4o-mini_text_retrieval_only_2024-08-13_11-51-31.csv',\n",
       " './logs/2024-08-13_11-51-31_gpt-4o-mini_text_retrieval_only/fusion_gpt-4o-mini_text_retrieval_only_2024-08-13_11-51-31.csv',\n",
       " './logs/2024-08-13_11-51-31_gpt-4o-mini_text_retrieval_only/hyde_gpt-4o-mini_text_retrieval_only_2024-08-13_11-51-31.csv']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-13T10:08:30.086306Z",
     "start_time": "2024-08-13T10:08:29.819888Z"
    }
   },
   "cell_type": "code",
   "source": [
    "folder = \"./logs/2024-08-13_11-51-31_gpt-4o-mini_text_retrieval_only\"\n",
    "keywords = [\"base\", \"rerank\", \"hybrid\", \"fusion\", \"hyde\"]\n",
    "files = get_filtered_and_sorted_filenames(folder, keywords)\n",
    "for filename in files:\n",
    "    filename = folder + \"/\" + filename\n",
    "\n",
    "control_path = \"documents.json\"\n",
    "\n",
    "name_columns = [\n",
    "    \"Node 1 Metadata: Name\",\n",
    "    \"Node 2 Metadata: Name\",\n",
    "    \"Node 3 Metadata: Name\"\n",
    "]\n",
    "\n",
    "id_columns = [\n",
    "    \"Node 1 ID\",\n",
    "    \"Node 2 ID\",\n",
    "    \"Node 3 ID\"\n",
    "]\n",
    "\n",
    "ratios_name = []\n",
    "comparisons_name = []\n",
    "ratios_id = []\n",
    "comparisons_id = []\n",
    "\n",
    "for file in files:\n",
    "    df = pd.read_csv(file, sep=';')\n",
    "    ratio_name, comparison_name = compare_nodes(df=df, control_path=control_path, columns=name_columns, type=\"name\")\n",
    "    ratio_id, comparison_id = compare_nodes(df=df, control_path=control_path, columns=id_columns, type=\"id\")\n",
    "    \n",
    "    ratios_name.append(ratio_name)\n",
    "    comparisons_name.append(comparison_name)\n",
    "    ratios_id.append(ratio_id)\n",
    "    comparisons_id.append(comparison_id)\n",
    "    \n",
    "# printing a nice table\n",
    "data = [\n",
    "    [\"ratio name\"]+ratios_name,\n",
    "    [\"ratio id\"]+ratios_id\n",
    "]\n",
    "\n",
    "print(tabulate(data, headers=[\"Text\", \"Jina\", \"Multilingual\", \"Cross\"], tablefmt=\"grid\"))"
   ],
   "id": "d60bf8977de3d9ed",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+----------+----------+----------------+---------+\n",
      "|            |          |     Text |     Jina |   Multilingual |   Cross |\n",
      "+============+==========+==========+==========+================+=========+\n",
      "| ratio name | 0.416667 | 0.416667 | 0.416667 |       0.416667 |     0.5 |\n",
      "+------------+----------+----------+----------+----------------+---------+\n",
      "| ratio id   | 0.416667 | 0.416667 | 0.25     |       0.333333 |     0.5 |\n",
      "+------------+----------+----------+----------+----------------+---------+\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-13T10:09:12.158383Z",
     "start_time": "2024-08-13T10:09:11.917927Z"
    }
   },
   "cell_type": "code",
   "source": [
    "folder = \"./logs/2024-08-13_11-51-31_gpt-4o-mini_text_retrieval_only\"\n",
    "keywords = [\"base\", \"rerank\", \"hybrid\", \"fusion\", \"hyde\"]\n",
    "files = get_filtered_and_sorted_filenames(folder, keywords)\n",
    "\n",
    "control_path = \"documents.json\"\n",
    "\n",
    "name_columns = [\n",
    "    \"Node 1 Metadata: Name\",\n",
    "    \"Node 2 Metadata: Name\",\n",
    "    \"Node 3 Metadata: Name\"\n",
    "]\n",
    "\n",
    "id_columns = [\n",
    "    \"Node 1 ID\",\n",
    "    \"Node 2 ID\",\n",
    "    \"Node 3 ID\"\n",
    "]\n",
    "\n",
    "ratios_name = []\n",
    "comparisons_name = []\n",
    "ratios_id = []\n",
    "comparisons_id = []\n",
    "\n",
    "for file in files:\n",
    "    df = pd.read_csv(file, sep=';')\n",
    "    ratio_name, comparison_name = compare_nodes(df=df, control_path=control_path, columns=name_columns, type=\"name\")\n",
    "    ratio_id, comparison_id = compare_nodes(df=df, control_path=control_path, columns=id_columns, type=\"id\")\n",
    "\n",
    "    ratios_name.append(ratio_name)\n",
    "    comparisons_name.append(comparison_name)\n",
    "    ratios_id.append(ratio_id)\n",
    "    comparisons_id.append(comparison_id)\n",
    "\n",
    "# printing a nice table\n",
    "data = [\n",
    "    [\"ratio name\"]+ratios_name,\n",
    "    [\"ratio id\"]+ratios_id\n",
    "]\n",
    "\n",
    "print(tabulate(data, headers=[\"Base\", \"Rerank\", \"Hybrid\", \"Fusion\", \"HyDE\"], tablefmt=\"grid\"))"
   ],
   "id": "60806c9d4172ee89",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+----------+----------+----------+--------+\n",
      "|            |     Base |   Rerank |   Hybrid |   Fusion |   HyDE |\n",
      "+============+==========+==========+==========+==========+========+\n",
      "| ratio name | 0.416667 | 0.416667 | 0.416667 | 0.416667 |    0.5 |\n",
      "+------------+----------+----------+----------+----------+--------+\n",
      "| ratio id   | 0.416667 | 0.416667 | 0.25     | 0.333333 |    0.5 |\n",
      "+------------+----------+----------+----------+----------+--------+\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-19T13:30:04.722131Z",
     "start_time": "2024-08-19T13:30:04.466440Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#folder = \"./logs/2024-08-19_14-09-05_gpt-4o-mini_multilingual_stsb-distilroberta-base_retrieval_only\"\n",
    "folder = \"./logs/2024-08-19_15-28-51_gpt-4o-mini_multilingual_msmarco-MiniLM-L12-en-de-v1_retrieval_only\"\n",
    "keywords = [\"base\", \"rerank\", \"hybrid\"]\n",
    "files = get_filtered_and_sorted_filenames(folder, keywords)\n",
    "\n",
    "control_path = \"documents.json\"\n",
    "\n",
    "rerank_n = 3\n",
    "name_columns = []\n",
    "id_columns = []\n",
    "for i in range(rerank_n):\n",
    "    name_columns.append(f\"Node {i+1} Metadata: Name\")\n",
    "    id_columns.append(f\"Node {i+1} ID\")\n",
    "\n",
    "\n",
    "ratios_name = []\n",
    "comparisons_name = []\n",
    "ratios_id = []\n",
    "comparisons_id = []\n",
    "\n",
    "for file in files:\n",
    "    df = pd.read_csv(file, sep=';')\n",
    "    ratio_name, comparison_name = compare_nodes(df=df, control_path=control_path, columns=name_columns, type=\"name\")\n",
    "    ratio_id, comparison_id = compare_nodes(df=df, control_path=control_path, columns=id_columns, type=\"id\")\n",
    "\n",
    "    ratios_name.append(ratio_name)\n",
    "    comparisons_name.append(comparison_name)\n",
    "    ratios_id.append(ratio_id)\n",
    "    comparisons_id.append(comparison_id)\n",
    "\n",
    "# printing a nice table\n",
    "data = [\n",
    "    [\"ratio name\"]+ratios_name,\n",
    "    [\"ratio id\"]+ratios_id\n",
    "]\n",
    "\n",
    "print(tabulate(data, headers=[\"Base\", \"Rerank\", \"Hybrid\"], tablefmt=\"grid\"))"
   ],
   "id": "cee3e89f77341b59",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+----------+----------+\n",
      "|            |   Base |   Rerank |   Hybrid |\n",
      "+============+========+==========+==========+\n",
      "| ratio name |   0.25 | 0.333333 | 0.333333 |\n",
      "+------------+--------+----------+----------+\n",
      "| ratio id   |   0.25 | 0.333333 | 0.333333 |\n",
      "+------------+--------+----------+----------+\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-19T13:26:29.365213Z",
     "start_time": "2024-08-19T13:26:29.361887Z"
    }
   },
   "cell_type": "code",
   "source": "comparisons_id[2]",
   "id": "351d032d98a96b60",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, True, True, True, False, True, True, False, False, True, False, False]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 32
  },
  {
   "cell_type": "markdown",
   "id": "7b84e032",
   "metadata": {},
   "source": [
    "# Calculating average times"
   ]
  },
  {
   "cell_type": "code",
   "id": "46ece596",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T10:25:52.529589Z",
     "start_time": "2024-08-06T10:25:52.522936Z"
    }
   },
   "source": [
    "query_times = df[\"query_time\"]\n",
    "generating_times = df[\"generating_time\"]\n",
    "total_times = df[\"total_time\"]\n",
    "\n",
    "# calculate averages\n",
    "avg_query_time = np.mean(query_times)\n",
    "avg_generating_time = np.mean(generating_times)\n",
    "avg_total_time = np.mean(total_times)\n",
    "\n",
    "# get maximum\n",
    "max_query_time = np.max(query_times)\n",
    "max_generating_time = np.max(generating_times)\n",
    "max_total_time = np.max(total_times)\n",
    "\n",
    "# get max ids\n",
    "max_query_id = query_times.idxmax()\n",
    "max_generating_id = generating_times.idxmax()\n",
    "max_total_id = total_times.idxmax()\n",
    "\n",
    "# get minimum\n",
    "min_query_time = np.min(query_times)\n",
    "min_generating_time = np.min(generating_times)\n",
    "min_total_time = np.min(total_times)\n",
    "\n",
    "# get min ids\n",
    "min_query_id = query_times.idxmin()\n",
    "min_generating_id = generating_times.idxmin()\n",
    "min_total_id = total_times.idxmin()"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "9b8b31fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T10:26:06.553231Z",
     "start_time": "2024-08-06T10:26:06.549361Z"
    }
   },
   "source": [
    "# Prepare data for table\n",
    "data = [\n",
    "    [\"Query Time (s)\", avg_query_time, max_query_time, min_query_time, max_query_id, min_query_id],\n",
    "    [\"Generating Time (s)\", avg_generating_time, max_generating_time, min_generating_time, max_generating_id, min_generating_id],\n",
    "    [\"Total Time (s)\", avg_total_time, max_total_time, min_total_time, max_total_id, min_total_id]\n",
    "]\n",
    "\n",
    "# Print table\n",
    "print(tabulate(data, headers=[\"Type\", \"Average\", \"Maximum\", \"Minimum\", \"Max ID\", \"Min ID\"], tablefmt=\"grid\"))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+-----------+------------+------------+----------+----------+\n",
      "| Type                |   Average |    Maximum |    Minimum |   Max ID |   Min ID |\n",
      "+=====================+===========+============+============+==========+==========+\n",
      "| Query Time (s)      |  0.018802 |  0.0277135 |  0.0139725 |        9 |        3 |\n",
      "+---------------------+-----------+------------+------------+----------+----------+\n",
      "| Generating Time (s) | 38.8156   | 96.108     | 12.0876    |       11 |        2 |\n",
      "+---------------------+-----------+------------+------------+----------+----------+\n",
      "| Total Time (s)      | 38.8344   | 96.1283    | 12.1091    |       11 |        2 |\n",
      "+---------------------+-----------+------------+------------+----------+----------+\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Calculating Token Usage",
   "id": "3c2f23ab325a6931"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T13:42:50.272608Z",
     "start_time": "2024-08-06T13:42:50.267115Z"
    }
   },
   "cell_type": "code",
   "source": [
    "embedding_tokens = df[\"embedding_tokens\"]\n",
    "prompt_tokens = df[\"prompt_tokens\"]\n",
    "completion_tokens = df[\"completion_tokens\"]\n",
    "total_tokens = df[\"total_tokens\"]\n",
    "\n",
    "# calculate averages\n",
    "avg_embedding_tokens = np.mean(embedding_tokens)\n",
    "avg_prompt_tokens = np.mean(prompt_tokens)\n",
    "avg_completion_tokens = np.mean(completion_tokens)\n",
    "avg_total_tokens = np.mean(total_tokens)\n",
    "\n",
    "# get maximum\n",
    "max_embedding_tokens = np.max(embedding_tokens)\n",
    "max_prompt_tokens = np.max(prompt_tokens)\n",
    "max_completion_tokens = np.max(completion_tokens)\n",
    "max_total_tokens = np.max(total_tokens)\n",
    "\n",
    "# get max ids\n",
    "max_embedding_id = embedding_tokens.idxmax()\n",
    "max_prompt_id = prompt_tokens.idxmax()\n",
    "max_completion_id = completion_tokens.idxmax()\n",
    "max_total_id = total_tokens.idxmax()\n",
    "\n",
    "# get minimum\n",
    "min_embedding_tokens = np.min(embedding_tokens)\n",
    "min_prompt_tokens = np.min(prompt_tokens)\n",
    "min_completion_tokens = np.min(completion_tokens)\n",
    "min_total_tokens = np.min(total_tokens)\n",
    "\n",
    "# get min ids\n",
    "min_embedding_id = embedding_tokens.idxmin()\n",
    "min_prompt_id = prompt_tokens.idxmin()\n",
    "min_completion_id = completion_tokens.idxmin()\n",
    "min_total_id = total_tokens.idxmin()\n",
    "\n",
    "# calculate cost\n",
    "prompt_costs_mini = 0.15 / 1_000_000\n",
    "completion_costs_mini = 0.6 / 1_000_000\n",
    "\n",
    "prompt_costs = 5 / 1_000_000\n",
    "completion_costs = 15 / 1_000_000\n",
    "\n",
    "avg_prompt_cost = avg_prompt_tokens * prompt_costs\n",
    "avg_completion_cost = avg_completion_tokens * completion_costs\n",
    "avg_total_cost = avg_prompt_cost + avg_completion_cost\n",
    "\n",
    "max_prompt_cost = max_prompt_tokens * prompt_costs\n",
    "max_completion_cost = max_completion_tokens * completion_costs\n",
    "max_total_cost = max_prompt_cost + max_completion_cost\n",
    "\n",
    "min_prompt_cost = min_prompt_tokens * prompt_costs\n",
    "min_completion_cost = min_completion_tokens * completion_costs\n",
    "min_total_cost = min_prompt_cost + min_completion_cost"
   ],
   "id": "d6d116e2dea1f6ab",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T13:42:53.751314Z",
     "start_time": "2024-08-06T13:42:53.747114Z"
    }
   },
   "cell_type": "code",
   "source": [
    "token_data = [\n",
    "    [\"Embedding\", avg_embedding_tokens, max_embedding_tokens, min_embedding_tokens, max_embedding_id, min_embedding_id, \"\", \"\", \"\"],\n",
    "    [\"Prompt\", avg_prompt_tokens, max_prompt_tokens, min_prompt_tokens, max_prompt_id, min_prompt_id, avg_prompt_cost, max_prompt_cost,min_prompt_cost],\n",
    "    [\"Completion\", avg_completion_tokens, max_completion_tokens, min_completion_tokens, max_completion_id, min_completion_id, avg_completion_cost, max_completion_cost, min_completion_cost],\n",
    "    [\"Total\", avg_total_tokens, max_total_tokens, min_total_tokens, max_total_id, min_total_id, avg_total_cost, max_total_cost, min_total_cost],\n",
    "]\n",
    "\n",
    "print(tabulate(token_data, headers=[\"Type\", \"Average\", \"Maximum\", \"Minimum\", \"Max ID\", \"Min ID\", \"Avg Cost\", \"Max Cost\", \"Min Cost\"], tablefmt=\"grid\"))"
   ],
   "id": "f0e0eee50601cf67",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+-----------+-----------+----------+----------+----------------------+----------------------+-----------------------+\n",
      "| Type       |   Average |   Maximum |   Minimum |   Max ID |   Min ID | Avg Cost             | Max Cost             | Min Cost              |\n",
      "+============+===========+===========+===========+==========+==========+======================+======================+=======================+\n",
      "| Embedding  |    17     |        28 |        10 |        6 |        2 |                      |                      |                       |\n",
      "+------------+-----------+-----------+-----------+----------+----------+----------------------+----------------------+-----------------------+\n",
      "| Prompt     |  1687     |      2225 |      1046 |        9 |        5 | 0.008435000000000002 | 0.011125000000000001 | 0.00523               |\n",
      "+------------+-----------+-----------+-----------+----------+----------+----------------------+----------------------+-----------------------+\n",
      "| Completion |   370.167 |       933 |        97 |       11 |        2 | 0.0055525            | 0.013995             | 0.0014550000000000001 |\n",
      "+------------+-----------+-----------+-----------+----------+----------+----------------------+----------------------+-----------------------+\n",
      "| Total      |  2057.17  |      2948 |      1311 |        9 |        5 | 0.013987500000000002 | 0.025120000000000003 | 0.006685              |\n",
      "+------------+-----------+-----------+-----------+----------+----------+----------------------+----------------------+-----------------------+\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# How to perform t-tests",
   "id": "af84647938248f95"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T11:36:48.935322Z",
     "start_time": "2024-08-06T11:36:48.933453Z"
    }
   },
   "cell_type": "code",
   "source": "from scipy.stats import ttest_ind",
   "id": "bc79b97733737ba5",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T11:37:49.257884Z",
     "start_time": "2024-08-06T11:37:48.980958Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_hybrid = pd.read_csv('./logs/2024-07-29_15-32-57_sauerkraut_hero_q6_jina_custom_prompt/hybrid_sauerkraut_hero_q6_jina_custom_prompt_2024-07-29_15-32-57.csv',\n",
    "                      sep=';')"
   ],
   "id": "37ed4b4060f3aabd",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T11:44:27.188050Z",
     "start_time": "2024-08-06T11:44:27.185098Z"
    }
   },
   "cell_type": "code",
   "source": [
    "hybrid_prompt_tokens = df_hybrid[\"prompt_tokens\"]\n",
    "print(ttest_ind(hybrid_prompt_tokens, prompt_tokens)) # equal_var=False if needed\n",
    "print(f\"{np.mean(hybrid_prompt_tokens)} || {avg_prompt_tokens}\")"
   ],
   "id": "19e5a96033c4a52f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_indResult(statistic=2.899162831701088, pvalue=0.008322323384283261)\n",
      "2144.75 || 1687.0\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "A t-test can only be performed if:\n",
    "1. the data is relatively normally distributed\n",
    "2. the samples have approximately equal variance\n",
    "\n",
    "If the datasets do not have equal variance, we can use the equal_var=False flag for the t-Test.\n",
    "\n",
    "I don't know yet what to do if the data is not normally distributed"
   ],
   "id": "5969a82eb411fca4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We can test if the data follows a normal distribution with the Shapiro-Wilk test. <br>\n",
    "Alternatively the Dâ€™Agostino K2 test can be used to measure Kurtosis and Skewness of a distribution.\n",
    "\n",
    "I know I learned when to which test in Sportscience, so I might want to look that up again.\n",
    "\n",
    "Both functions are taken from this tutorial: <br>\n",
    "https://datagy.io/normality-test-python/"
   ],
   "id": "7db77812a2dd044b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T11:54:13.284743Z",
     "start_time": "2024-08-06T11:54:13.281323Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from scipy.stats import shapiro\n",
    "\n",
    "def shapiro_test(data, alpha = 0.05):\n",
    "    stat, p = shapiro(data)\n",
    "    if p > alpha:\n",
    "        print('Data looks Gaussian')\n",
    "    else:\n",
    "        print('Data look does not look Gaussian')"
   ],
   "id": "52ae8bf189ea0faa",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T11:54:47.425508Z",
     "start_time": "2024-08-06T11:54:47.422014Z"
    }
   },
   "cell_type": "code",
   "source": "shapiro_test(prompt_tokens)",
   "id": "b8cd990719de72f9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data looks Gaussian\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T11:57:55.495065Z",
     "start_time": "2024-08-06T11:57:55.491363Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from scipy.stats import normaltest\n",
    "\n",
    "def dagostino_test(data, alpha = 0.05):\n",
    "    stat, p = normaltest(data)\n",
    "    if p > alpha:\n",
    "        print('Data looks Gaussian')\n",
    "    else:\n",
    "        print('Data does not look Gaussian')"
   ],
   "id": "433fb7848f1634f7",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T11:58:02.700938Z",
     "start_time": "2024-08-06T11:58:02.698523Z"
    }
   },
   "cell_type": "code",
   "source": "shapiro_test(prompt_tokens)",
   "id": "bbda6f74d9525cd3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data looks Gaussian\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We can check for equal variance using the Levene's test\n",
    "\n",
    "Taken from this tutorial: <br>\n",
    "https://datagy.io/python-levene-test/"
   ],
   "id": "cffe9da10cd7639f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T12:04:12.262756Z",
     "start_time": "2024-08-06T12:04:12.259924Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from scipy.stats import levene\n",
    "\n",
    "def levene_test(group1, group2):\n",
    "    levene_stat, p_value = levene(group1, group2)\n",
    "    if p_value < 0.05:\n",
    "        print(\"Variances are significantly different.\")\n",
    "    else:\n",
    "        print(\"Variances are likely similar.\")"
   ],
   "id": "8e62f4f6af878b9a",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T12:04:35.831669Z",
     "start_time": "2024-08-06T12:04:35.827372Z"
    }
   },
   "cell_type": "code",
   "source": "levene_test(prompt_tokens, hybrid_prompt_tokens)",
   "id": "37bd8f6ec1d724e2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variances are likely similar.\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2be981010a88e2fa"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
